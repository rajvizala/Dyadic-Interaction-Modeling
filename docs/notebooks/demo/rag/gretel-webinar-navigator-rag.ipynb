{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d92922d4"
      },
      "source": [
        "<a target=\"_parent\" href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/demo/rag/gretel-webinar-navigator-rag.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji3TjU3-jg7P"
      },
      "outputs": [],
      "source": [
        "local_dir = \"aistudio-copilot-sample\"\n",
        "![ -d $local_dir ] || git clone https://github.com/Azure/aistudio-copilot-sample.git $local_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFa_bgPLk223"
      },
      "outputs": [],
      "source": [
        "%pip install -Uqq gretel_client langchain tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQq4zr3wfkq5"
      },
      "source": [
        "### 1. Read and chunk dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPlIydzsfkq5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "CHUNK_SIZE = 1500 #tokens\n",
        "CHUNK_OVERLAP = 0\n",
        "MIN_CHUNK_CHARS = 2000\n",
        "\n",
        "def find_files_by_extension(directory, extension):\n",
        "    texts = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(extension):\n",
        "                file_path = os.path.join(root, file)\n",
        "                with open(file_path) as f:\n",
        "                    text = f.read()\n",
        "                    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "                        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
        "                    )\n",
        "                    chunks = text_splitter.split_text(text)\n",
        "                    for chunk in chunks:\n",
        "                        if len(chunk) > MIN_CHUNK_CHARS:\n",
        "                            texts.append([file_path, chunk])\n",
        "    return texts\n",
        "\n",
        "target_path = Path(local_dir) / 'data' / '3-product-info'\n",
        "target_extension = \".md\"\n",
        "texts = find_files_by_extension(target_path, target_extension)\n",
        "\n",
        "print(f\"Found {len(set([t[0] for t in texts]))} files. Extracted {len(texts)} chunks with tiktoken\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_lO629Ofkq5"
      },
      "source": [
        "### 2. Create synthetic Q-T pairs with Gretel Navigator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-pF3kkU2BS9"
      },
      "outputs": [],
      "source": [
        "from gretel_client import Gretel\n",
        "\n",
        "gretel = Gretel(api_key=\"prompt\", cache=True, validate=True)\n",
        "\n",
        "navigator = gretel.factories.initialize_navigator_api(\"tabular\", backend_model=\"gretelai-google/gemini-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFrEVMFSfkq6"
      },
      "outputs": [],
      "source": [
        "# Base instruction for dataset creation\n",
        "INTRO_PROMPT = (\n",
        "    \"From the source text below, create a dataset with the following columns:\\n\"\n",
        ")\n",
        "\n",
        "# Columns for question, context, and truth\n",
        "COLUMN_DETAILS = (\n",
        "    \"* `question`: Ask a set of unique questions related to the topic that a customer might ask. \"\n",
        "    \"Questions should be relatively complex and specific enough to be addressed in a short answer.\\n\"\n",
        "    \"* `context`: Copy the exact sentence(s) from the source text and surrounding details from where the answer can be derived. T\\n\"\n",
        "    \"* `truth`: Respond to the question with a clear, textbook quality answer that provides relevant details to fully address the question.\\n\"\n",
        ")\n",
        "\n",
        "# Combining all parts into the final prompt\n",
        "PROMPT = (\n",
        "    INTRO_PROMPT +\n",
        "    COLUMN_DETAILS\n",
        ")\n",
        "\n",
        "# Optionally, print the prompt to verify its format\n",
        "print(PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M_xmL4AoG7I"
      },
      "outputs": [],
      "source": [
        "# Separate diversification prompts\n",
        "SEED_PROMPT_1 = (\n",
        "    \"* `topic`: Select topics from Basic Information, Pricing and Warranty, Usage, Technical Details, \"\n",
        "    \"Sustainability, Security, and Future Updates.\\n\"\n",
        ")\n",
        "\n",
        "SEED_PROMPT_2 = (\n",
        "    \"* `user_profile`: The complexity level of the question and truth, categorized into beginner, intermediate, and expert.\\n\"\n",
        "    \"  - Beginner users are about building foundational knowledge about the product and ask about basic features, benefits, and uses of the product.\\n\"\n",
        "    \"  - Intermediate users have a deep understanding of the product and are focusing on practical applications, comparisons with other products, and intermediate-level features and benefits.\\n\"\n",
        "    \"  - Expert users demonstrate in-depth technical knowledge, strategic application, and advanced troubleshooting. This level is for those who need to know the product inside and out, possibly for roles in sales, technical support, or product development.\\n\"\n",
        ")\n",
        "\n",
        "SEED_PROMPT_3 = (\n",
        "    \"* `language`: This is the language in which the question and truth columns should be phrased. Chose from English, Dutch, French, and Spanish.\\n\"\n",
        ")\n",
        "\n",
        "# Combining all parts into the final prompt\n",
        "PROMPT = (\n",
        "    INTRO_PROMPT +\n",
        "    SEED_PROMPT_1 +\n",
        "    SEED_PROMPT_2 +\n",
        "    SEED_PROMPT_3 +\n",
        "    COLUMN_DETAILS\n",
        ")\n",
        "\n",
        "# Optionally, print the prompt to verify its format\n",
        "print(PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHmRONlxsVk0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create synthetic records\n",
        "MAX_DOCS = 1\n",
        "SAMPLES_PER_DOC = 10\n",
        "\n",
        "GENERATE_PARAMS = {\n",
        "    \"num_records\": SAMPLES_PER_DOC,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.9,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for text in texts[:MAX_DOCS]:\n",
        "    df_doc = navigator.generate(f\"{PROMPT}\\n\\n{text[1]}\", **GENERATE_PARAMS)\n",
        "    df_doc['file_path'] = text[0]\n",
        "    df = pd.concat([df, df_doc], ignore_index=True)\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "display(df.sample(n=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR1Bz1UNfkq6"
      },
      "source": [
        "### 3. Human Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kixhbmWrfkq7"
      },
      "outputs": [],
      "source": [
        "### helper function\n",
        "\n",
        "from ipywidgets import widgets, Layout, VBox, HBox, HTML\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Initialize global variables\n",
        "index = 0\n",
        "keep_df = pd.DataFrame(columns=df.columns)\n",
        "discard_df = pd.DataFrame(columns=df.columns)\n",
        "finished_labeling = False\n",
        "\n",
        "def display_title():\n",
        "    title_html = \"\"\"\n",
        "    <style>\n",
        "        .title {\n",
        "            font-family: Arial, sans-serif;\n",
        "            color: #2E86C1;\n",
        "            font-size: 18px;\n",
        "        }\n",
        "    </style>\n",
        "    <div class=\"title\">Human in the Loop Validation Stage</div>\n",
        "    \"\"\"\n",
        "    display(HTML(title_html))\n",
        "\n",
        "def update_progress():\n",
        "    progress_info = f\"Progress: {index + 1}/{len(df)} | Kept: {len(keep_df)} | Discarded: {len(discard_df)}\"\n",
        "    return widgets.Label(value=progress_info)\n",
        "\n",
        "def create_buttons():\n",
        "    keep_button = widgets.Button(description=\"Keep\", layout=Layout(width='100px'))\n",
        "    discard_button = widgets.Button(description=\"Discard\", layout=Layout(width='100px'))\n",
        "    finished_button = widgets.Button(description=\"Finished\", layout=Layout(width='100px'))\n",
        "    keep_all_button = widgets.Button(description=\"Keep All\",\n",
        "                                     layout=Layout(width='100px', margin='0 0 0 20px'),  # Add margin for separation\n",
        "                                     style={'button_color': 'lightgreen'})  # Change button color\n",
        "\n",
        "    keep_button.on_click(on_keep_button_click)\n",
        "    discard_button.on_click(on_discard_button_click)\n",
        "    finished_button.on_click(on_finished_button_click)\n",
        "    keep_all_button.on_click(on_keep_all_button_click)  # Set the click handler for the new button\n",
        "\n",
        "    return HBox([keep_button, discard_button, finished_button, keep_all_button])  # Include the new button\n",
        "\n",
        "def on_keep_button_click(b):\n",
        "    global keep_df, index\n",
        "    keep_df = pd.concat([keep_df, df.iloc[[index]]], ignore_index=True)\n",
        "    index += 1\n",
        "    human_evaluate()\n",
        "\n",
        "def on_discard_button_click(b):\n",
        "    global discard_df, index\n",
        "    discard_df = pd.concat([discard_df, df.iloc[[index]]], ignore_index=True)\n",
        "    index += 1\n",
        "    human_evaluate()\n",
        "\n",
        "def on_finished_button_click(b):\n",
        "    global finished_labeling\n",
        "    finished_labeling = True\n",
        "    human_evaluate()\n",
        "\n",
        "def on_keep_all_button_click(b):\n",
        "    global keep_df, finished_labeling\n",
        "    keep_df = df.copy()  # Set keep_df to all records from df\n",
        "    finished_labeling = True\n",
        "    human_evaluate()  # Optionally call human_evaluate() to update the UI or handle the finish state\n",
        "\n",
        "def display_row_details(row):\n",
        "    text_widgets = [widgets.HTML(value=f\"<b>{col}:</b> {row.iloc[0][col]}\") for col in df.columns]\n",
        "    return VBox(text_widgets)\n",
        "\n",
        "def human_evaluate():\n",
        "    global index\n",
        "    clear_output(wait=True)\n",
        "    display_title()\n",
        "\n",
        "    if index >= len(df) or finished_labeling:\n",
        "        display(HTML(\"<h3>Labeling Complete!</h3>\"))\n",
        "        return\n",
        "\n",
        "    row = df.iloc[[index]]\n",
        "    progress_label = update_progress()\n",
        "    buttons = create_buttons()\n",
        "    row_details = display_row_details(row)\n",
        "\n",
        "    display(VBox([progress_label, buttons, row_details]))\n",
        "\n",
        "# Initial call to start the human evaluation process\n",
        "human_evaluate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnjys8sfkq7"
      },
      "source": [
        "### 4. Writing out Q-T pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz7Jn3M-2os-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "jsonl_file_path = 'gretel_samples.jsonl'\n",
        "\n",
        "# Filter the DataFrame to keep only 'question' and 'ground_truth' columns\n",
        "keep_df_filtered = keep_df[['question', 'truth']]\n",
        "\n",
        "# Export the filtered DataFrame to JSONL\n",
        "with open(jsonl_file_path, 'w') as jsonl_file:\n",
        "    for _, row in keep_df_filtered.iterrows():\n",
        "        json.dump(row.to_dict(), jsonl_file)\n",
        "        jsonl_file.write('\\n')\n",
        "\n",
        "# Read and print the JSONL file contents with nice formatting\n",
        "with open(jsonl_file_path, 'r', encoding='utf-8') as jsonl_file:\n",
        "    for line in jsonl_file:\n",
        "        json_obj = json.loads(line)\n",
        "        # Use ensure_ascii=False here as well to print Unicode characters correctly\n",
        "        print(json.dumps(json_obj, indent=4, ensure_ascii=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "azure_venv3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}